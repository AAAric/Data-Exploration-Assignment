---
title: "Data Exploration Assignment"
author: "Aric Cheng"
date: "2/23/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(purrr)
library(dplyr)
library(tidyverse)
library(lubridate)
library(vtable)
library(jtools)
library(ggthemes)
library(grid)
library(gridExtra)
library(lattice)
```

## Data Cleaning

```{r}
df <- list.files(path = 'Lab3_Rawdata', 
                   pattern = 'trend', full.names = TRUE) %>% lapply(read_csv) 

data <- bind_rows(df)
```

Standardize the Google Trends Data

```{r}
data <- data %>% 
  group_by(schname, keyword) %>%
  mutate(index_std = (index - mean(index, na.rm = TRUE))/sd(index, na.rm = TRUE))
```

Omitting duplicate college names

```{r}
id_name_link <- read.csv('Lab3_Rawdata/id_name_link.csv')
id_name_link <- id_name_link %>% 
  group_by(schname) %>% 
  mutate(N = n()) %>% 
  filter(N == 1)
```

Converting all column names to lowercase for data to join together

```{r}
scorecard <- read.csv("Lab3_Rawdata/Most+Recent+Cohorts+(Scorecard+Elements).csv")
names(scorecard) <- tolower(names(scorecard))
```

Convert earnings to numeric values

```{r}
scorecard$md_earn_wne_p10.reported.earnings = as.numeric(as.character(scorecard$md_earn_wne_p10.reported.earnings))
```

Joining trends data with the id_name_link using schname; then joining the scorecard data into a single dataframe

```{r}
Trends <- id_name_link %>% 
  left_join(data, by = 'schname')
trendsXscorecard <- Trends %>% left_join(scorecard, by = c("unitid" = "unitid", "opeid" = "opeid"))
```

Dropping any irrelevant variables to simplify the dataset for our analysis and keeping a select few variables we would need

```{r}
trendsXscorecard <- trendsXscorecard %>% select(unitid, opeid, schname, keyword, monthorweek, preddeg, md_earn_wne_p10.reported.earnings, index_std)
```

Filter for Colleges that provides a Bachelor Program 

```{r}
bach_scorecard <- trendsXscorecard %>% filter (preddeg == 3, na.rm = TRUE)
```

## Analysis

To establish the definition of 'high-earning' and 'low-earning' colleges, I decided to use the 3rd quartile (75%) of earnings as the threshold for what is considered 'high-earning' and will be assigned a '1' variable; 'low earnings' will be everything below that which will be assigned a '0' variable. Using a higher quartile will target those colleges who consistently produce high earning graduates rather than those that varies from year to year. 

We also adjusted the 3rd quartile value for inflation based on the average dollar value in the 2013-2016 timeframe to today's value.

```{r}
quantile(bach_scorecard$md_earn_wne_p10.reported.earnings, na.rm = TRUE)
Inflation_Adj_Income = 49100*1.19
bach_scorecard$EarnVal <- ifelse(bach_scorecard$md_earn_wne_p10.reported.earnings >= Inflation_Adj_Income, "1", "0")
```

Setting the reporting by month and omitting any NA's

```{r}
bachelor_month <- bach_scorecard %>%
  mutate(date = as.Date(str_sub(monthorweek, 1, 10))) %>%
  group_by(schname, keyword) %>%
  mutate(index_std = (index_std - mean(index_std, na.rm = TRUE))/sd(index_std, na.rm = TRUE)) %>%
  group_by(month = floor_date(date, "month"), opeid, md_earn_wne_p10.reported.earnings, EarnVal)%>%
  summarize(index_std = mean(index_std, na.rm = TRUE))
bachelor_month <- drop_na(bachelor_month)
```

Given that the release date of the scorecard was released in the start of September 2015, we will be setting logical dummy variables to indicate whether the google search result was before/after that data and whether it is a high earning or low earning college.
```{r}
Analysis <- bachelor_month %>%
  mutate(TF = md_earn_wne_p10.reported.earnings >= Inflation_Adj_Income, TFadjust = month >= 
           as.Date("2015-09-01"))
```

Difference-in-difference analysis was applied. 

```{r}
diff_analysis <- lm(index_std ~ TF * TFadjust, data = Analysis)
export_summs(diff_analysis, digits = 2)
```

The results indicate that google searches increased 9% for 'high-earning' colleges after the release of the scorecard. 

## Graph

```{r}
Analysis %>%
  select(month, index_std, EarnVal) %>%
  mutate(EarnVal = as.factor(EarnVal)) -> tidy_table

tidy_table %>%
  group_by(month, EarnVal) %>%
  summarize(index_mean = mean(index_std)) %>%
  ggplot(aes(month, index_mean, group = EarnVal, color=EarnVal)) +
  geom_line(size = 1) +
  labs(
    title = "Google Searches Over Time",
    x = "Date",
    y = "Google Trends Index"
  ) +
  theme(legend.title = element_blank()) +
  scale_color_discrete(labels = (c("Low Earning Colleges",
                                   "High Earning Colleges"))) +
  geom_vline(xintercept = as.numeric(as.Date("2015-09-01")),
             size = 1,
             color = "yellow", 
             alpha = 0.5) +
  geom_vline(xintercept = as.numeric(as.Date("2014-09-01")),
             size = 1,
             color = "purple", 
             alpha = 0.5) +
  geom_vline(xintercept = as.numeric(as.Date("2013-09-01")),
             size = 1,
             color = "purple", 
             alpha = 0.5)
```

## Commentary

Developed a visual that reflects the Google Search Trends over a period of time from 2013 to 2016. It is separated into two lines, red representing the low earning colleges and blue representing the high earning colleges. I have also placed 3 vertical lines to indicate the same period of time in the prior years. The yellow line is when the scorecard was implemented, and we can see a more pronounced increase in searches for high-earning colleges upon its release and thereafter. Another thing to note is that the overall searches are downtrending due to less enrollment during this period for continued education, and google searches for colleges seem to be seasonal based on the recurring trend of peaking during September. 

Overall, the scorecard did have a positive impact on the searches of high-earning colleges as prospective students are potentially more educated during the search process. Coming to this conclusion, I realized that the scorecard disclosed other critical information as well such as graduation rates and average financial aid received per student which could have resulted into a backdoor type of scenario for increased searches. For future analysis, I believe pulling those datapoints in as well as extending the number of datapoints to at least an additional 2 years after the point of release, as we see that college searches are seasonal, would have helped us gain a greater understanding of the story.




